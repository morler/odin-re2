package main

import "core:fmt"
import "core:time"
import "../regexp"

main :: proc() {
	fmt.println("=== UTF-8 ä¼˜åŒ–æµ‹è¯• ===")

	// æµ‹è¯•åŸºç¡€ UTF-8 è§£ç 
	test_utf8_decoding()

	// æµ‹è¯• ASCII å¿«é€Ÿè·¯å¾„
	test_ascii_fast_path()

	// æµ‹è¯• Unicode å­—ç¬¦å¤„ç†
	test_unicode_processing()

	// æµ‹è¯•æ€§èƒ½
	test_utf8_performance()

	// æµ‹è¯•é”™è¯¯å¤„ç†
	test_error_handling()

	fmt.println("\næ‰€æœ‰ UTF-8 ä¼˜åŒ–æµ‹è¯•å®Œæˆ!")
}

test_utf8_decoding :: proc() {
	fmt.println("\n--- UTF-8 è§£ç æµ‹è¯• ---")

	// æµ‹è¯• ASCII å­—ç¬¦
	ascii_data := []u8{'H', 'e', 'l', 'l', 'o'}
	char, bytes, valid := regexp.decode_utf8_char_fast(ascii_data, 0)
	assert(char == 'H' && bytes == 1 && valid, "ASCII 'H' should decode correctly")

	// æµ‹è¯• 2å­—èŠ‚ UTF-8 (Ã©)
	utf8_2byte := []u8{0xC3, 0xA9}  // Ã©
	char, bytes, valid = regexp.decode_utf8_char_fast(utf8_2byte, 0)
	assert(char == 'Ã©' && bytes == 2 && valid, "UTF-8 'Ã©' should decode correctly")

	// æµ‹è¯• 3å­—èŠ‚ UTF-8 (ä¸­)
	utf8_3byte := []u8{0xE4, 0xB8, 0xAD}  // ä¸­
	char, bytes, valid = regexp.decode_utf8_char_fast(utf8_3byte, 0)
	assert(char == 'ä¸­' && bytes == 3 && valid, "UTF-8 'ä¸­' should decode correctly")

	// æµ‹è¯• 4å­—èŠ‚ UTF-8 (ğŸ˜Š)
	utf8_4byte := []u8{0xF0, 0x9F, 0x98, 0x8A}  // ğŸ˜Š
	char, bytes, valid = regexp.decode_utf8_char_fast(utf8_4byte, 0)
	assert(char == 'ğŸ˜Š' && bytes == 4 && valid, "UTF-8 'ğŸ˜Š' should decode correctly")

	fmt.println("[PASS] UTF-8 è§£ç æµ‹è¯•")
}

test_ascii_fast_path :: proc() {
	fmt.println("\n--- ASCII å¿«é€Ÿè·¯å¾„æµ‹è¯• ---")

	// åˆ›å»ºæ··åˆ ASCII/Unicode å­—ç¬¦ä¸²
	mixed_text := "Hello, ä¸–ç•Œ! This is a test with ASCII and æ¼¢å­—."
	text_bytes := transmute([]u8)mixed_text

	// æµ‹è¯•å¿«é€Ÿè·¯å¾„
	ascii_count := 0
	unicode_count := 0

	pos := 0
	for pos < len(text_bytes) {
		char, bytes, _ := regexp.decode_utf8_char_fast(text_bytes, pos)
		if char < 128 {
			ascii_count += 1
		} else {
			unicode_count += 1
		}
		pos += bytes
	}

	fmt.printf("ASCII å­—ç¬¦: %d\n", ascii_count)
	fmt.printf("Unicode å­—ç¬¦: %d\n", unicode_count)
	fmt.printf("ASCII æ¯”ä¾‹: %.1f%%\n", f64(ascii_count) / f64(ascii_count + unicode_count) * 100)

	assert(ascii_count > 0, "Should have ASCII characters")
	assert(unicode_count > 0, "Should have Unicode characters")

	fmt.println("[PASS] ASCII å¿«é€Ÿè·¯å¾„æµ‹è¯•")
}

test_unicode_processing :: proc() {
	fmt.println("\n--- Unicode å¤„ç†æµ‹è¯• ---")

	// æµ‹è¯• UTF-8 è¿­ä»£å™¨
	text := "Hello ä¸–ç•Œ! ğŸ˜Š"
	text_bytes := transmute([]u8)text

	iter := regexp.make_utf8_iterator_fast(text_bytes)
	char_count := 0

	for regexp.utf8_has_more_fast(&iter) {
		char := regexp.utf8_peek_fast(&iter)
		char_count += 1
		regexp.utf8_advance_fast(&iter)
	}

	// æ‰‹åŠ¨è®¡ç®—æœŸæœ›çš„å­—ç¬¦æ•°
	// "Hello" = 5 å­—ç¬¦, " " = 1 å­—ç¬¦, "ä¸–ç•Œ" = 2 å­—ç¬¦, "!" = 1 å­—ç¬¦, " " = 1 å­—ç¬¦, "ğŸ˜Š" = 1 å­—ç¬¦
	expected_count := 11  // 5 + 1 + 2 + 1 + 1 + 1
	assert(char_count == expected_count, fmt.tprintf("Should have %d characters, got %d", expected_count, char_count))

	// æµ‹è¯•å­—ç¬¦è®¡æ•°
	count := regexp.count_utf8_chars_fast(text_bytes)
	assert(count == expected_count, fmt.tprintf("Character count should be %d, got %d", expected_count, count))

	fmt.printf("å­—ç¬¦è®¡æ•°: %d\n", count)
	fmt.println("[PASS] Unicode å¤„ç†æµ‹è¯•")
}

test_utf8_performance :: proc() {
	fmt.println("\n--- UTF-8 æ€§èƒ½æµ‹è¯• ---")

	// åˆ›å»ºæµ‹è¯•æ•°æ® (æ··åˆ ASCII/Unicode)
	// ç”±äº Odin ä¸æ”¯æŒéå¸¸é‡å­—ç¬¦ä¸²è¿æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨å•ä¸ªå­—ç¬¦ä¸²
	test_text := "The quick brown fox jumps over the lazy dog. Hello ä¸–ç•Œ! è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚Bonjour le monde!"
	text_bytes := transmute([]u8)test_text

	iterations := 100000

	// æµ‹è¯•è§£ç æ€§èƒ½
	start := time.now()
	decoded_chars := 0
	for i in 0..<iterations {
		pos := 0
		for pos < len(text_bytes) {
			char, bytes, _ := regexp.decode_utf8_char_fast(text_bytes, pos)
			if char != 0 {
				decoded_chars += 1
			}
			pos += bytes
		}
	}
	decode_time := time.since(start)

	// æµ‹è¯•è¿­ä»£å™¨æ€§èƒ½
	start = time.now()
	iterated_chars := 0
	for i in 0..<iterations {
		iter := regexp.make_utf8_iterator_fast(text_bytes)
		for regexp.utf8_has_more_fast(&iter) {
			regexp.utf8_peek_fast(&iter)
			iterated_chars += 1
			regexp.utf8_advance_fast(&iter)
		}
	}
	iterator_time := time.since(start)

	fmt.printf("è§£ç æ€§èƒ½: %v (%.2f ns/op)\n", decode_time, f64(decode_time) / f64(iterations * len(text_bytes)))
	fmt.printf("è¿­ä»£å™¨æ€§èƒ½: %v (%.2f ns/op)\n", iterator_time, f64(iterator_time) / f64(iterations * len(text_bytes)))

	assert(decoded_chars == iterated_chars, "Both methods should decode same number of characters")

	fmt.println("[PASS] UTF-8 æ€§èƒ½æµ‹è¯•")
}

test_error_handling :: proc() {
	fmt.println("\n--- é”™è¯¯å¤„ç†æµ‹è¯• ---")

	// æµ‹è¯•æ— æ•ˆçš„ UTF-8 åºåˆ—
	invalid_utf8 := []u8{0x80, 0xC0, 0xE0, 0x80}  // Various invalid sequences

	error_count := 0
	pos := 0
	for pos < len(invalid_utf8) {
		_, _, valid := regexp.decode_utf8_char_fast(invalid_utf8, pos)
		if !valid {
			error_count += 1
		}
		pos += 1  // Move one byte at a time to test error recovery
	}

	assert(error_count > 0, "Should detect invalid UTF-8 sequences")

	// æµ‹è¯•ä¸å®Œæ•´åºåˆ—
	incomplete := []u8{0xC3}  // Incomplete 2-byte sequence
	char, bytes, valid := regexp.decode_utf8_char_fast(incomplete, 0)
	assert(!valid, "Incomplete sequence should be invalid")
	assert(bytes == 1, "Should consume one byte for incomplete sequence")

	fmt.printf("æ£€æµ‹åˆ° %d ä¸ªæ— æ•ˆ UTF-8 åºåˆ—\n", error_count)
	fmt.println("[PASS] é”™è¯¯å¤„ç†æµ‹è¯•")
}

assert :: proc(condition: bool, message: string) {
	if !condition {
		fmt.printf("æ–­è¨€å¤±è´¥: %s\n", message)
		panic("æµ‹è¯•å¤±è´¥")
	}
}